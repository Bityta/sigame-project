# Техническое задание: Работа нейронки с E2E тестами

## Цель
Нейронка должна автоматически анализировать результаты e2e тестов, находить проблемы в продакшене и помогать их исправлять.

## Основные принципы работы

### 1. Итеративный подход (КРИТИЧНО)
**Работать итеративно**: запускать тесты по одному, анализировать результат, исправлять или продолжать.

Цикл работы:
1. Запустить один тест
2. Посмотреть результат
3. Если падает → найти проблему → исправить → вернуться к шагу 1
4. Если проходит → перейти к следующему тесту

**Правила**:
- Не запускать все тесты сразу
- После каждого исправления обязательно запускать тест снова
- Не переходить к следующему тесту, пока текущий не проходит
- Не накапливать проблемы - исправлять сразу

### 2. Анализ результатов тестов
- Запускать тесты: `npm test` или `playwright test` (по одному)
- Анализировать результаты из `test-results/` и `playwright-report/`
- Читать логи ошибок из `test-run.log` и файлов `.log`
- Изучать скриншоты и видео из `test-results/` при падении тестов
- Проверять trace файлы для детального анализа

### 3. Поиск проблем
- Тесты проверяют реальный продакшен на `http://89.169.139.21` (из `playwright.config.ts`)
- Код в проде может быть не идеальным - это нормально
- Нужно находить реальные баги, а не проблемы в тестах
- Приоритет: проблемы в проде > проблемы в тестах

### 4. Источники информации для диагностики

#### 4.1 Обязательные источники (в порядке приоритета)
1. **README.md** в корне проекта (ГЛАВНОЕ ТЗ ПРОЕКТА)
   - **Это полное техническое задание всего проекта**
   - Архитектура системы (схемы, диаграммы)
   - Описание всех сервисов (Auth, Lobby, Game, Pack)
   - Полные API спецификации (REST, WebSocket, gRPC)
   - Game State Machine (все состояния и переходы)
   - База данных (схемы, таблицы)
   - Нефункциональные требования (производительность, безопасность)
   - Форматы данных и протоколы
   - **ВСЯ информация о том, как должна работать система**
   - **Использовать как основной источник истины при диагностике проблем**

2. **Код в репозитории**
   - Frontend: `frontend/src/`
   - Backend сервисы: `services/auth/`, `services/game/`, `services/lobby/`, `services/packs/`
   - E2E тесты: `services/e2e-tests/tests/`
   - Helpers: `services/e2e-tests/tests/helpers/`
   - **Важно**: Сверяться с README.md для понимания ожидаемого поведения

3. **SSH подключение к серверу**
   - Сервер: `89.169.139.21`
   - Проверять логи сервисов
   - Проверять состояние контейнеров Docker
   - Проверять метрики Prometheus/Grafana
   - Проверять базы данных
   - **Важно**: Сравнивать фактическое поведение с описанием в README.md

#### 4.2 Дополнительные источники
- `COVERAGE_ANALYSIS.md` - покрытие тестами
- `PROBLEMS_FOUND.md` - ранее найденные проблемы
- `TEST_ISSUES.md` - известные проблемы с тестами
- `TEST_CASES.md` - описание тест-кейсов

### 5. Очевидные ошибки в проде
Если видишь очевидную ошибку в проде:
- **Немедленно сообщи пользователю**
- Укажи конкретное место (файл, строка, компонент)
- Опиши проблему кратко и понятно
- Предложи решение, если оно очевидно

Примеры очевидных ошибок:
- Синтаксические ошибки в коде
- Неправильные типы данных
- Отсутствующие проверки на null/undefined
- Неправильная обработка ошибок
- Проблемы с состоянием React компонентов
- Ошибки в логике Game State Machine

### 6. Правила написания кода
- **НЕ писать комментарии** в коде
- Код должен быть самодокументируемым
- Использовать понятные имена переменных и функций
- Следовать существующему стилю кода в проекте

### 7. Итеративный процесс работы с тестами (детально)

**Ключевой принцип**: Работать итеративно - запускать тест, анализировать результат, исправлять или продолжать.

#### Общий цикл работы:
```
1. Запустить тест → 
2. Посмотреть результат → 
3. Если падает: найти проблему → исправить → вернуться к шагу 1
4. Если проходит: перейти к следующему тесту
```

#### Правила итеративного подхода:
- **Один тест за раз**: запускать тесты по одному, не все сразу
- **Немедленная проверка**: после каждого исправления запускать тест снова
- **Не накапливать проблемы**: исправлять проблемы сразу, не откладывать
- **Проверка после исправления**: всегда запускать тест после любого изменения кода
- **Переход к следующему**: только после успешного прохождения текущего теста

#### Пример итеративного цикла:
```
Итерация 1:
  → Запускаю test:room.spec.ts:6 (отображение информации о комнате)
  → Тест падает: "Element `.room-page__code-value` not found"
  → Анализирую: проверяю RoomPage.tsx
  → Нахожу проблему: элемент не рендерится
  → Исправляю код

Итерация 2:
  → Запускаю тот же тест снова
  → Тест проходит ✅
  → Перехожу к следующему тесту

Итерация 3:
  → Запускаю test:room.spec.ts:17 (копирование кода комнаты)
  → Тест проходит ✅
  → Перехожу к следующему тесту
```

### 8. Процесс работы с упавшим тестом

#### Шаг 1: Запуск теста
1. Запустить конкретный тест: `npm test -- tests/room.spec.ts:6`
2. Дождаться завершения выполнения
3. Получить результат (успех/падение)

#### Шаг 2: Анализ результата
1. Если тест прошел → перейти к следующему тесту
2. Если тест упал → продолжить диагностику:
   - Прочитать сообщение об ошибке из логов
   - Посмотреть скриншот/видео падения теста
   - Изучить trace файл (если доступен)
   - Понять, что именно проверял тест

#### Шаг 3: Диагностика проблемы
1. **Прочитать README.md** - понять, как должна работать система согласно ТЗ
2. Прочитать соответствующий тест-файл - понять, что именно проверяется
3. Изучить helper функции, которые использует тест
4. Проверить код фронтенда/бэкенда, который тестируется
5. Сравнить фактическое поведение с описанием в README.md
6. При необходимости подключиться по SSH и проверить логи

#### Шаг 4: Определение причины
1. **Сверка с README.md**: соответствует ли поведение ТЗ?
2. Проблема в проде (не соответствует ТЗ) → исправить код
3. Проблема в тесте (тест проверяет не то, что в ТЗ) → исправить тест
4. Неопределенность → перечитать README.md, подключиться по SSH, проверить логи

#### Шаг 5: Исправление и проверка
1. Внести изменения в код (без комментариев)
2. **Запустить тест снова** для проверки исправления
3. Если тест все еще падает → вернуться к шагу 2 (анализ новой ошибки)
4. Если тест проходит → перейти к следующему тесту

### 9. Структура проекта

```
sigame-project/
├── README.md                    # ГЛАВНОЕ ТЗ ПРОЕКТА (полное техническое задание)
├── frontend/                    # React фронтенд
│   └── src/
│       ├── pages/               # Страницы приложения
│       ├── features/            # Фичи (auth, game, room)
│       └── shared/              # Общие компоненты
├── services/
│   ├── auth/                    # Auth сервис (Go)
│   ├── game/                    # Game сервис (Go)
│   ├── lobby/                   # Lobby сервис (Kotlin)
│   ├── packs/                   # Pack сервис (Python)
│   └── e2e-tests/               # E2E тесты
│       ├── tests/               # Тесты
│       │   ├── *.spec.ts        # Playwright тесты
│       │   └── helpers/         # Helper функции
│       ├── playwright.config.ts # Конфигурация Playwright
│       ├── PROBLEMS_FOUND.md    # Найденные проблемы
│       └── COVERAGE_ANALYSIS.md # Анализ покрытия
└── deployment/                  # Скрипты деплоя
```

### 10. Типичные проблемы и их решение

#### 8.1 Проблемы с WebSocket
- Проверить логи game сервиса
- Проверить состояние WebSocket соединения
- Проверить Game State Machine переходы

#### 8.2 Проблемы с аутентификацией
- Проверить логи auth сервиса
- Проверить JWT токены
- Проверить refresh token механизм

#### 8.3 Проблемы с комнатами
- Проверить логи lobby сервиса
- Проверить состояние комнаты в БД
- Проверить WebSocket события

#### 8.4 Проблемы с UI
- Проверить React компоненты
- Проверить состояние компонента
- Проверить обработку событий

### 11. Команды для диагностики

#### Локально - итеративный запуск тестов
```bash
cd services/e2e-tests

# Запуск одного конкретного теста (ИТЕРАТИВНО)
npm test -- tests/room.spec.ts:6                    # Тест на строке 6
npm test -- tests/room.spec.ts:17                    # Тест на строке 17
npm test -- tests/room.spec.ts -g "отображение"      # Тест по названию

# Запуск группы тестов
npm run test:room                 # Все тесты комнаты
npm run test:game                 # Все тесты игры
npm test                          # Все тесты (не рекомендуется для итеративной работы)

# Отладка
npm run test:ui                   # Запустить в UI режиме (удобно для отладки)
npm run test:debug                # Запустить в debug режиме
npm run test:headed               # Запустить с видимым браузером
```

**Важно**: Для итеративной работы использовать запуск одного теста, а не всех сразу!

#### На сервере (через SSH)
```bash
ssh user@89.169.139.21
docker ps                         # Проверить контейнеры
docker logs <service-name>        # Логи сервиса
docker exec -it <container> sh    # Войти в контейнер
```

### 12. Дополнительные рекомендации

#### 12.1 Приоритизация
1. Критичные баги (игра не запускается, пользователи не могут войти)
2. Важные баги (функциональность работает неправильно)
3. Мелкие баги (UI проблемы, edge cases)

#### 12.2 Документирование найденных проблем
- Обновлять `PROBLEMS_FOUND.md` при нахождении новых проблем
- Указывать статус: найден → исправлено → проверено

#### 12.3 Работа с флаки тестами
- Если тест падает нестабильно → проверить race conditions
- Увеличить таймауты только если это действительно нужно
- Проверить синхронизацию между клиентом и сервером

#### 12.4 Проверка после исправления
- Запустить конкретный упавший тест
- Запустить связанные тесты (например, все тесты комнаты)
- При необходимости запустить все тесты

### 13. Примеры работы

#### Пример 1: Итеративное исправление проблемы с элементом

**Итерация 1: Запуск теста**
```
→ Запускаю: npm test -- tests/room.spec.ts:6
→ Результат: ❌ Тест упал
→ Ошибка: "Element `.room-page__code-value` not found"
```

**Итерация 2: Анализ и исправление**
```
→ Читаю README.md: проверяю описание комнаты ожидания
→ Читаю тест: room.spec.ts:14
→ Проверяю код: frontend/src/pages/room/RoomPage.tsx
→ Сравниваю с README.md: код комнаты должен отображать код
→ Нахожу проблему: элемент не рендерится при определенных условиях
→ Исправляю условие рендеринга (согласно ТЗ в README.md)
→ Запускаю тест снова: npm test -- tests/room.spec.ts:6
```

**Итерация 3: Проверка исправления**
```
→ Результат: ✅ Тест прошел
→ Перехожу к следующему тесту: tests/room.spec.ts:17
```

#### Пример 2: Итеративное исправление проблемы с WebSocket

**Итерация 1: Запуск теста**
```
→ Запускаю: npm test -- tests/room.spec.ts:79
→ Результат: ❌ Тест упал
→ Ошибка: "Timeout waiting for game start"
```

**Итерация 2: Диагностика**
```
→ Читаю README.md: проверяю описание Game Service и WebSocket API
→ Читаю тест: room.spec.ts:99
→ Сверяю с README.md: как должно работать автоматическое начало игры
→ Подключаюсь по SSH: ssh user@89.169.139.21
→ Проверяю логи: docker logs game-service
→ Вижу проблему: WebSocket событие не отправляется (не соответствует ТЗ)
```

**Итерация 3: Исправление**
```
→ Проверяю код: services/game/internal/...
→ Нахожу проблему: неправильная обработка события
→ Исправляю код
→ Запускаю тест снова: npm test -- tests/room.spec.ts:79
```

**Итерация 4: Проверка исправления**
```
→ Результат: ✅ Тест прошел
→ Перехожу к следующему тесту
```

#### Пример 3: Несколько итераций для сложной проблемы

**Итерация 1: Первая попытка**
```
→ Запускаю тест → падает
→ Исправляю очевидную проблему
→ Запускаю снова → все еще падает
```

**Итерация 2: Глубокая диагностика**
```
→ Перечитываю README.md: детально изучаю описание проблемной части системы
→ Анализирую новую ошибку
→ Сверяю с README.md: что должно происходить согласно ТЗ
→ Подключаюсь по SSH
→ Проверяю логи и метрики
→ Нахожу реальную причину (несоответствие ТЗ)
```

**Итерация 3: Правильное исправление**
```
→ Исправляю найденную проблему
→ Запускаю тест → ✅ проходит
```

### 14. Чеклист при работе с упавшим тестом

- [ ] **Прочитал README.md** - понял, как должна работать система согласно ТЗ
- [ ] Прочитал сообщение об ошибке
- [ ] Посмотрел скриншот/видео
- [ ] Изучил код теста
- [ ] Изучил helper функции
- [ ] Проверил код фронтенда/бэкенда
- [ ] **Сверил фактическое поведение с README.md**
- [ ] При необходимости подключился по SSH
- [ ] Определил причину проблемы (проблема в проде или в тесте)
- [ ] Исправил код (без комментариев, согласно ТЗ в README.md)
- [ ] Запустил тест для проверки
- [ ] Обновил `PROBLEMS_FOUND.md` если нужно

## Дополнительные предложения

### 15. Автоматизация и улучшения процесса

#### 15.1 Сравнение с предыдущими запусками
- Сохранять результаты тестов в формате JSON
- Сравнивать текущий запуск с предыдущим
- Отмечать новые проблемы (не было раньше)
- Отмечать исправленные проблемы (было, теперь нет)
- Отмечать регрессии (было исправлено, снова появилось)

#### 15.2 Автоматическое определение типа проблемы
- Классифицировать проблемы по категориям:
  - Frontend UI/UX
  - Backend API
  - WebSocket/Real-time
  - Database
  - Authentication
  - Performance
  - Race conditions
- Это поможет быстрее находить нужный код для исправления

#### 15.3 Автоматическое исправление простых проблем
- Автоматически исправлять очевидные проблемы:
  - Отсутствующие проверки на null/undefined
  - Неправильные селекторы в тестах
  - Проблемы с таймаутами (если это не критично)
  - Простые синтаксические ошибки
- Всегда спрашивать подтверждение перед автоисправлением

#### 15.4 Анализ паттернов проблем
- Находить повторяющиеся проблемы
- Группировать похожие ошибки
- Предлагать рефакторинг для устранения паттерна проблем
- Например: если много тестов падает из-за таймаутов → проверить производительность

#### 15.5 Предсказание проблем
- Анализировать код перед запуском тестов
- Находить потенциальные проблемы:
  - Отсутствующие обработчики ошибок
  - Потенциальные race conditions
  - Проблемы с состоянием компонентов
  - Неправильные переходы в Game State Machine
- Предупреждать о возможных проблемах заранее

#### 15.6 Интеграция с мониторингом
- Использовать метрики из Prometheus/Grafana
- Связывать падения тестов с метриками:
  - Высокая задержка WebSocket → проблемы с производительностью
  - Много ошибок в логах → проблемы с обработкой ошибок
  - Высокая нагрузка на CPU → проблемы с производительностью

#### 15.7 Автоматическое создание отчетов
- Создавать отчеты о найденных проблемах
- Группировать по приоритету и категориям
- Предлагать план исправления
- Оценивать время на исправление

#### 15.8 Работа с флаки тестами
- Отслеживать нестабильные тесты
- Запускать их несколько раз для проверки стабильности
- Если тест падает >30% раз → это проблема, а не флаки
- Если тест падает <10% раз → возможно флаки, но все равно проверить

#### 15.9 Автоматическое обновление документации
- Обновлять `PROBLEMS_FOUND.md` автоматически
- Обновлять `COVERAGE_ANALYSIS.md` при добавлении новых тестов
- Создавать changelog исправлений

#### 15.10 Приоритизация исправлений
- Автоматически определять приоритет проблемы:
  - Критичные: блокируют основную функциональность
  - Высокие: влияют на важную функциональность
  - Средние: влияют на второстепенную функциональность
  - Низкие: косметические проблемы
- Предлагать порядок исправления

#### 15.11 Анализ покрытия тестами
- Отслеживать, какие части кода не покрыты тестами
- Предлагать новые тесты для непокрытых участков
- Использовать `COVERAGE_ANALYSIS.md` как базу

#### 15.12 Работа с зависимостями
- Понимать связи между тестами
- Если падает один тест → проверить связанные тесты
- Если падает группа тестов → найти общую причину

#### 15.13 Использование AI для анализа
- Использовать семантический поиск для поиска похожих проблем
- Анализировать код с помощью LLM для понимания логики
- Предлагать альтернативные решения проблем

#### 15.14 Интеграция с CI/CD
- Автоматически запускать тесты при изменениях
- Блокировать деплой при критичных проблемах
- Создавать автоматические отчеты для команды

#### 15.15 Работа с версиями
- Отслеживать, в какой версии появилась проблема
- Отслеживать, в какой версии проблема была исправлена
- Связывать проблемы с коммитами

### 16. Метрики успешности работы

Отслеживать:
- Количество найденных проблем
- Количество исправленных проблем
- Время на исправление проблемы
- Процент успешных тестов
- Количество регрессий
- Количество новых проблем

### 17. Примеры улучшений процесса

#### Пример 1: Автоматическое исправление
```
Проблема: Тест падает из-за отсутствия проверки на null
Действие: Автоматически добавляю проверку
Результат: Тест проходит, проблема исправлена
```

#### Пример 2: Предсказание проблемы
```
Анализ кода: Вижу потенциальную race condition
Предупреждение: "Возможна проблема с синхронизацией в GamePage.tsx:123"
Действие: Предлагаю добавить проверку перед запуском теста
```

#### Пример 3: Группировка проблем
```
Найдено 5 похожих проблем с WebSocket таймаутами
Общая причина: Высокая задержка на сервере
Решение: Оптимизировать обработку WebSocket событий
```

### 18. Рекомендации по внедрению

1. Начать с базовой функциональности (пункты 1-12)
2. Постепенно добавлять автоматизацию (пункты 13.1-13.5)
3. Интегрировать с мониторингом (пункты 13.6-13.7)
4. Добавить продвинутые функции (пункты 13.8-13.15)

### 19. Ограничения и предостережения

- Не исправлять код без понимания контекста
- Всегда проверять исправления запуском тестов
- Не удалять тесты без веской причины
- Не увеличивать таймауты без понимания причины
- Всегда сообщать пользователю о критичных проблемах

